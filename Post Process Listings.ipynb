{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3aa6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15215cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file_path = r\"/Users/dhruvarora/Documents/Smollan : Google/Version_1.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Column to count lines\n",
    "column_name = \"Detected Text\"\n",
    "\n",
    "# Filter out rows that contain \"< Previous\" or \"Next >\"\n",
    "exclude_patterns = [\"< Previous\", \"Next >\"]\n",
    "filtered_df = df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "for pattern in exclude_patterns:\n",
    "    filtered_df = filtered_df[~filtered_df[column_name].str.contains(pattern, na=False)]\n",
    "\n",
    "# Filter out rows where \"Deal of the Day\" or \"Limited time Deal\" appears more than 2 times\n",
    "deal_pattern = \"Deal of the Day\"\n",
    "filtered_df = filtered_df[filtered_df[column_name].str.count(deal_pattern) <= 2]\n",
    "\n",
    "limited_time_deal_pattern = \"Limited time Deal\"\n",
    "filtered_df = filtered_df[filtered_df[column_name].str.count(limited_time_deal_pattern) <= 2]\n",
    "\n",
    "# Remove rows with empty or whitespace-only text\n",
    "filtered_df = filtered_df[~filtered_df[column_name].str.strip().eq(\"\")]\n",
    "\n",
    "# Filter out rows where total character count is less than 100\n",
    "filtered_df = filtered_df[filtered_df[column_name].apply(len) >= 100]\n",
    "\n",
    "# Reset the index after filtering\n",
    "filtered_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbf72ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = filtered_df.groupby(\"Image Name\")\n",
    "\n",
    "# Function to reset \"Order\" within each group\n",
    "def reset_order(group):\n",
    "    group = group.reset_index(drop=True)  # Reset the index for each group\n",
    "    group[\"Order\"] = group.index + 1  # Update the \"Order\" to be sequential\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "df_corrected = grouped.apply(reset_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea402c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027a43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected['Order'] = df_corrected.groupby('Image Name')['Order'].transform(lambda x: len(x) - x + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f51c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected.to_csv(r'/Users/dhruvarora/Desktop/corrected_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5280cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "021e611d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define regular expression patterns\n",
    "product_pattern = re.compile(\n",
    "    r\"(.*?)(?=(Limited time deal|Deal of the Day|bought in past month|\\.\\.\\.|(\\d{1,3}(,\\d{3})*)\\s*M\\.R\\.P|(\\d{1,3}(,\\d{3})*)\\s*âœ”prime))\",\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "a_price_pattern = re.compile(r\"\\*?(\\d{1,3}(,\\d{3})*)\\*?\\s*(?=(M\\.R\\.P|\\.\\.\\.|\\.\\.\\.))\")\n",
    "b_price_pattern = r\"\\*?(\\d{1,3}(,\\d{3})*)\\*? M\\.R\\.P\"\n",
    "discounted_price_pattern = re.compile(f\"{a_price_pattern}|{b_price_pattern}\")\n",
    "mrp_pattern = re.compile(r\"M\\.R\\.P:\\s*([^ ]+)\")\n",
    "discount_pattern = re.compile(r\"\\(\\d+%\\s*off\\)\")\n",
    "delivery_by_pattern = re.compile(r\"Get it by\\s*[^\\n]+\")\n",
    "\n",
    "# Extract information from detected text\n",
    "def extract_info(text):\n",
    "    product_match = re.search(product_pattern, text)\n",
    "    product_details = product_match.group().strip() if product_match else None\n",
    "    \n",
    "    discounted_price_match = re.search(discounted_price_pattern, text)\n",
    "    discounted_price = discounted_price_match.group().strip() if discounted_price_match else None\n",
    "\n",
    "    original_price_match = re.search(mrp_pattern, text)\n",
    "    original_price = original_price_match.group(1).strip() if original_price_match else None\n",
    "\n",
    "    discount_match = re.search(discount_pattern, text)\n",
    "    discount = discount_match.group().strip() if discount_match else None\n",
    "\n",
    "    delivery_by_match = re.search(delivery_by_pattern, text)\n",
    "    delivery_by = delivery_by_match.group().strip() if delivery_by_match else None\n",
    "    \n",
    "    # Assign \"Other Details\" only if text is not empty or whitespace\n",
    "    other_details = text if text.strip() else None\n",
    "\n",
    "    return {\n",
    "        \"Product\": product_details,\n",
    "        \"Discounted Price\": discounted_price,\n",
    "        \"Original Price\": original_price,\n",
    "        \"Discount\": discount,\n",
    "        \"Delivery By\": delivery_by,\n",
    "        \"Other Details\": other_details,  # Assign only if text is not empty\n",
    "    }\n",
    "\n",
    "# Apply the function to create new columns from \"Detected Text\"\n",
    "df_extracted = df['Detected Text'].apply(extract_info).apply(pd.Series)\n",
    "\n",
    "# Assign to original DataFrame with specified columns\n",
    "df[['Product', 'DiscountedPrice', 'OriginalPrice', 'Discount', 'DeliveryBy', 'OtherDetails']] = df_extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382ac392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InterOrder'] = df['Image Name'].str.rsplit('_', n=1).str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6053ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InterOrder'] = df['InterOrder'].str.split('.', n=1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45b0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Order':'IntraOrder', 'Detected Text': 'RawText', 'Bucket Link': 'ImageLink', 'Product':'ProductName', 'Image Link':'ImageLink', 'Image Name': 'ImageName'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "981a879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Listing_Id'] = df['ImageName']+'_'+df['ProductName']+'_'+df['InterOrder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "660627fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the 'region' and 'producttype'\n",
    "def extract_info(value):\n",
    "    # Extract the region between the first and second underscores\n",
    "    region_pattern = r\"_(.*?)_\"  # Look for text between the first and second underscores\n",
    "    region_match = re.search(region_pattern, value)\n",
    "    region = region_match.group(1) if region_match else None\n",
    "    \n",
    "    # Extract the producttype between a number with an underscore and before '_listing'\n",
    "    producttype_pattern = r\"_\\d+_(.*)_listing\"  # Match text between a number with underscore and '_listing'\n",
    "    producttype_match = re.search(producttype_pattern, value)\n",
    "    producttype = producttype_match.group(1) if producttype_match else None\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Region': region,\n",
    "        'ProductType': producttype,\n",
    "    })\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['Region', 'ProductType']] = df['ImageName'].apply(extract_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "032f8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def extract_date_from_url(url):\n",
    "    # Regular expression to find the date pattern\n",
    "    date_pattern = re.compile(r'\\d{2}-\\d{2}-\\d{2}')\n",
    "    \n",
    "    # Extract the date from the URL\n",
    "    match = date_pattern.search(url)\n",
    "    if match:\n",
    "        # Extracted date string\n",
    "        date_str = match.group(0)\n",
    "        \n",
    "        # Convert the date string to a datetime object\n",
    "        date_obj = datetime.strptime(date_str, '%d-%m-%y')\n",
    "        \n",
    "        # Format the date in SQL date-time format\n",
    "        sql_date = date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return sql_date\n",
    "    else:\n",
    "        return None # Return None if no date is found\n",
    "\n",
    "# Apply the function to the 'Image Link' column and create a new column 'Date'\n",
    "df['Date'] = df['ImageLink'].apply(extract_date_from_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c023fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['ImageName', 'IntraOrder', 'RawText', 'ImageLink', 'ProductName', 'DiscountedPrice', 'OriginalPrice', 'Discount', 'DeliveryBy', 'OtherDetails', 'InterOrder', 'Listing_Id', 'Region', 'ProductType', 'Date']\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d311e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'/Users/dhruvarora/Desktop/corrected_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5a560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e49ac921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from urllib.parse import quote_plus\n",
    "\n",
    "# csv_file = r\"/Users/dhruvarora/Desktop/corrected_output.csv\"\n",
    "# user = quote_plus(\"u781023547_shashwat\")\n",
    "# password = quote_plus(\"consti@123C\")\n",
    "# host = \"srv1326.hstgr.io\"\n",
    "# port = \"3306\"\n",
    "# database = \"u781023547_harmony_paas\"\n",
    "\n",
    "# connection_string = (\n",
    "#     f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}\"\n",
    "# )\n",
    "# engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# df.to_sql('my_table', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee7c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3284b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SQL query to be executed\n",
    "# query = \"SELECT * FROM my_table\"\n",
    "\n",
    "# # Read the result of the SQL query into a DataFrame\n",
    "# newdf = pd.read_sql_query(query, engine)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0ea43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39507c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46386eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d234222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e809b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
